from sentence_transformers import SentenceTransformer
import numpy as np

# ğŸ“Œ KoSentenceBERT ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')

# ğŸ“Œ ë‹¨ì–´/ë¬¸ì¥ ì„ë² ë”© ìƒì„±
sentences = ["ëŠë¼í•¨", "ê¹Œë¥´ë³´ë‚˜ë¼", "ì¹˜ì¦ˆ", "ëƒ‰ë©´"]
embeddings = model.encode(sentences)

# ğŸ“Œ ì„ë² ë”© í™•ì¸ (ì°¨ì›: 768)
for sentence, embedding in zip(sentences, embeddings):
    print(f"'{sentence}' ì„ë² ë”© ì°¨ì›: {embedding.shape}")

# ğŸ“Œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
def cosine_similarity(vec1, vec2):
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

# ğŸ“Š ìœ ì‚¬ë„ ê³„ì‚°
sim = cosine_similarity(embeddings[0], embeddings[1])  # "ë˜¥ìŸì´" vs "ì‹±í¬ëŒ€"
sim2 = cosine_similarity(embeddings[0], embeddings[2])  # "ë˜¥ìŸì´" vs "ë³€ê¸°"
sim3 = cosine_similarity(embeddings[0], embeddings[3])  # "ë˜¥ìŸì´" vs "í•™ìƒíšŒì¥"

print(f"'{sentences[0]}'ê³¼ '{sentences[1]}'ì˜ ìœ ì‚¬ë„: {sim:.4f}")
print(f"'{sentences[0]}'ê³¼ '{sentences[2]}'ì˜ ìœ ì‚¬ë„: {sim2:.4f}")
print(f"'{sentences[0]}'ê³¼ '{sentences[3]}'ì˜ ìœ ì‚¬ë„: {sim3:.4f}")
